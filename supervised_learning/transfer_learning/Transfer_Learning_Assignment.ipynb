{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense\n",
    "import keras\n",
    "from tensorflow.keras import Sequential\n",
    "import keras_metrics as km\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23591810 (90.00 MB)\n",
      "Trainable params: 4098 (16.01 KB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2 # specifies the number of classes to be classified\n",
    "\n",
    "# Then add the new models \n",
    "\n",
    "new_model = Sequential()\n",
    "new_model.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n",
    "new_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# since first layer is already trained, restrict/freeze its retraining\n",
    "\n",
    "new_model.layers[0].trainable = False\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 512)               14714688  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14715714 (56.14 MB)\n",
      "Trainable params: 1026 (4.01 KB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "v16_model = Sequential()\n",
    "#Add the VGG16 model to our new sequential\n",
    "v16_model.add(VGG16(include_top=False, pooling='avg', weights='imagenet'))\n",
    "#add a dense layer to this new model after the convolutions.\n",
    "v16_model.add(Dense(num_classes, activation='softmax'))\n",
    "#freeze the top layers of our model (vgg16 layers)\n",
    "v16_model.layers[0].trainable = False\n",
    "v16_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Mobile net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenet_1.00_224 (Functi  (None, 1024)              3228864   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3230914 (12.32 MB)\n",
      "Trainable params: 2050 (8.01 KB)\n",
      "Non-trainable params: 3228864 (12.32 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobile_net = Sequential()\n",
    "mobile_net.add(MobileNet(include_top=False, pooling='avg', weights='imagenet'))\n",
    "#add a dense layer to this new model after the convolutions.\n",
    "mobile_net.add(Dense(num_classes, activation='softmax'))\n",
    "#freeze the top layers of our model (vgg16 layers)\n",
    "mobile_net.layers[0].trainable = False\n",
    "mobile_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile resnet model model\n",
    "precision = km.categorical_precision()\n",
    "new_model.compile (optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "v16_model.compile (optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "mobile_net.compile (optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and perfom Augmentation using data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 images belonging to 2 classes.\n",
      "Found 2023 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#load the image data\n",
    "\n",
    "#first, declare the required image size \n",
    "image_size = 150\n",
    "# The image data generator is used to augment our dataset to make sure that our model does not see the same image twice. This is especially important given that we have a relatively small dataset, hence our model is prone to overfitting\n",
    "#Entropic capacity of a model. How much capacity is your model allowed to store\n",
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                    rotation_range=40,\n",
    "                                    zoom_range=0.2,\n",
    "                                    width_shift_range = 0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    vertical_flip=False)\n",
    "\n",
    "train_generator = data_generator.flow_from_directory('../input/Cats_and_dogs/training_set/training_set', target_size=(image_size, image_size),\n",
    "                                                     batch_size = 200, \n",
    "                                                     class_mode = 'categorical')\n",
    "validation_generator = data_generator.flow_from_directory('../input/Cats_and_dogs/test_set/test_set', target_size=(image_size, image_size),\n",
    "                                                     batch_size = 100, \n",
    "                                                     class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and adjust the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Fitting the Resnet model\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "6/6 [==============================] - 118s 18s/step - loss: 1.1969 - accuracy: 0.6692 - val_loss: 0.3044 - val_accuracy: 0.8645\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 82s 15s/step - loss: 0.2463 - accuracy: 0.8942 - val_loss: 0.2351 - val_accuracy: 0.9030\n",
      "Fitting the VGG16 model\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 247s 47s/step - loss: 7.7756 - accuracy: 0.7025 - val_loss: 0.9736 - val_accuracy: 0.9145\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 318s 59s/step - loss: 0.7734 - accuracy: 0.9183 - val_loss: 0.9541 - val_accuracy: 0.9055\n",
      "Fitting the Mobile net model\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 87s 15s/step - loss: 2.2398 - accuracy: 0.4808 - val_loss: 3.2895 - val_accuracy: 0.5010\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 70s 13s/step - loss: 2.7679 - accuracy: 0.5085 - val_loss: 1.5524 - val_accuracy: 0.5415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2911126bd10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model to the data \n",
    "validation_steps= validation_generator.n // validation_generator.batch_size\n",
    "print(validation_steps)\n",
    "print('Fitting the Resnet model')\n",
    "new_model.fit(train_generator, epochs=2, steps_per_epoch=6, validation_data=validation_generator, validation_steps=validation_steps)\n",
    "print('Fitting the VGG16 model')\n",
    "v16_model.fit(train_generator, epochs= 2, steps_per_epoch=6, validation_data=validation_generator, validation_steps=validation_steps)\n",
    "print('Fitting the Mobile net model')\n",
    "mobile_net.fit(train_generator,epochs=2, steps_per_epoch=6, validation_data=validation_generator, validation_steps=validation_steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 87s 4s/step\n",
      "21/21 [==============================] - 199s 9s/step\n",
      "21/21 [==============================] - 34s 1s/step\n",
      "classification report for resnet model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.52      0.50      1011\n",
      "           1       0.48      0.45      0.47      1012\n",
      "\n",
      "    accuracy                           0.49      2023\n",
      "   macro avg       0.49      0.49      0.48      2023\n",
      "weighted avg       0.49      0.49      0.48      2023\n",
      "\n",
      "classification report for vgg16 model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.45      0.47      1011\n",
      "           1       0.49      0.54      0.52      1012\n",
      "\n",
      "    accuracy                           0.49      2023\n",
      "   macro avg       0.49      0.49      0.49      2023\n",
      "weighted avg       0.49      0.49      0.49      2023\n",
      "\n",
      "classification report for mobile net model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.95      0.65      1011\n",
      "           1       0.50      0.05      0.09      1012\n",
      "\n",
      "    accuracy                           0.50      2023\n",
      "   macro avg       0.50      0.50      0.37      2023\n",
      "weighted avg       0.50      0.50      0.37      2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "y_pred_new_model = np.argmax(new_model.predict(validation_generator), axis=1)\n",
    "y_pred_v16 = np.argmax(v16_model.predict(validation_generator), axis=1)\n",
    "y_pred_mob_net = np.argmax(mobile_net.predict(validation_generator), axis=1)\n",
    "\n",
    "print('classification report for resnet model')\n",
    "print(classification_report(y_true, y_pred_new_model))\n",
    "print('classification report for vgg16 model')\n",
    "print(classification_report(y_true, y_pred_v16))\n",
    "print('classification report for mobile net model')\n",
    "print(classification_report(y_true, y_pred_mob_net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:5818: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 467s 20s/step - loss: 0.1820 - binary_accuracy: 0.9367 - val_loss: 0.2384 - val_binary_accuracy: 0.9465\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 433s 22s/step - loss: 0.0858 - binary_accuracy: 0.9685 - val_loss: 0.1351 - val_binary_accuracy: 0.9645\n",
      "Epoch 1/2\n",
      "20/20 [==============================] - 957s 48s/step - loss: 1.1071 - binary_accuracy: 0.5359 - val_loss: 0.6901 - val_binary_accuracy: 0.5320\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 790s 40s/step - loss: 0.7631 - binary_accuracy: 0.5343 - val_loss: 0.7773 - val_binary_accuracy: 0.5010\n",
      "Epoch 1/2\n",
      "20/20 [==============================] - 117s 5s/step - loss: 0.3280 - binary_accuracy: 0.8725 - val_loss: 1.3508 - val_binary_accuracy: 0.6645\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 103s 5s/step - loss: 0.1858 - binary_accuracy: 0.9273 - val_loss: 0.7944 - val_binary_accuracy: 0.7840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2934c1c72d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with tf.device('/GPU:0'):\n",
    "    #Unfreeze the base_model layers\n",
    "new_model.layers[0].trainable = True\n",
    "# Due to the large size of the data_set, halve the steps per epoch to reduce training time\n",
    "steps_per_epoch = len(train_generator)//2\n",
    "\n",
    "new_model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.0001),  # Very low learning rate\n",
    "                loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=[keras.metrics.BinaryAccuracy()])\n",
    "new_model.fit(train_generator, epochs=2, steps_per_epoch=steps_per_epoch, validation_data=validation_generator, validation_steps=validation_steps)\n",
    "   \n",
    "v16_model.layers[0].trainable = True\n",
    " # Due to the large size of the data_set, halve the steps per epoch to reduce training time\n",
    "steps_per_epoch = len(train_generator)//2\n",
    "\n",
    "v16_model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.0001),  # Very low learning rate\n",
    "                loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=[keras.metrics.BinaryAccuracy()])\n",
    "v16_model.fit(train_generator, epochs=2, steps_per_epoch=steps_per_epoch, validation_data=validation_generator, validation_steps=validation_steps)\n",
    "\n",
    "mobile_net.layers[0].trainable = True\n",
    "    # Due to the large size of the data_set, halve the steps per epoch to reduce training time\n",
    "steps_per_epoch = len(train_generator)//2\n",
    "\n",
    "mobile_net.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.0001),  # Very low learning rate\n",
    "                loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=[keras.metrics.BinaryAccuracy()])\n",
    "mobile_net.fit(train_generator, epochs=2, steps_per_epoch=steps_per_epoch, validation_data=validation_generator, validation_steps=validation_steps)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
